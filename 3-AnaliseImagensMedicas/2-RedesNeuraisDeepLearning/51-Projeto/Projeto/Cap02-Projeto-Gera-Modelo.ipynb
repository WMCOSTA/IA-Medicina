{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Análise de Imagens Médicas com Inteligência Artificial</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVOz5H1mGAnR"
   },
   "source": [
    "### Projeto - Aplicação Web Para Deploy do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/projeto.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyBM6BzBFWJK"
   },
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacote para uso da linha de comando\n",
    "!pip install -q -U prompt_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "dSdDciVNG4C1",
    "outputId": "a809b0cd-e3ad-4554-cfeb-12cb32172753"
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "# Imports para manipulação e visualização de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports para manipulação de imagens\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import shutil\n",
    "import imageio\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports para Deep Learning\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "\n",
    "# Imports para cálculo de métricas e outras tarefas\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# As novas versões do Pandas e Matplotlib trazem diversas mensagens de aviso ao desenvolvedor. Vamos desativar isso.\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checando o Hardware Disponível no Servidor da DSA - CPU e GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os dispositivos disponiveis\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se por acaso não aparecer para você todas as GPUs, reinstale o TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall tensorflow\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Número Disponível de GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista o código de cada GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Local de Armazenamento das Imagens de Raio-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista o conteúdo do diretório\n",
    "os.listdir('/media/datasets/IAMED/Cap02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios para os 2 grupos de imagens\n",
    "imagens_shen = '/media/datasets/IAMED/Cap02/ChinaSet_AllFiles/CXR_png/'\n",
    "imagens_mont = '/media/datasets/IAMED/Cap02/MontgomerySet/CXR_png/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava a lista de imagens em cada pasta\n",
    "shen_image_list = os.listdir(imagens_shen)\n",
    "mont_image_list = os.listdir(imagens_mont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando e Carregando as Imagens de Raio-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dataframes com as listas das imagens\n",
    "df_shen = pd.DataFrame(shen_image_list, columns = ['image_id'])\n",
    "df_mont = pd.DataFrame(mont_image_list, columns = ['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove da lista o nome 'Thumbs.db'\n",
    "df_shen = df_shen[df_shen['image_id'] != 'Thumbs.db']\n",
    "df_mont = df_mont[df_mont['image_id'] != 'Thumbs.db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice para e evitar erros mais tarde\n",
    "df_shen.reset_index(inplace = True, drop = True)\n",
    "df_mont.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo a Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para selecionar o 4º índice no final da string (nome do arquivo)\n",
    "# Exemplo: CHNCXR_0470_1.png --> 1 é o label, significa que Tuberculose está presente na imagem.\n",
    "\n",
    "def extrair_target(x):\n",
    "    \n",
    "    target = int(x[-5])\n",
    "    \n",
    "    if target == 0:\n",
    "        return 'Normal'\n",
    "    if target == 1:\n",
    "        return 'Tuberculose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando label aos dataframe\n",
    "df_shen['target'] = df_shen['image_id'].apply(extrair_target)\n",
    "df_mont['target'] = df_mont['image_id'].apply(extrair_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shenzen Dataset\n",
    "df_shen['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montgomery Dataset\n",
    "df_mont['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para visualizar as imagens\n",
    "def visualiza_images(col_name, figure_cols, df, caminho_imagens):\n",
    "\n",
    "    # Define as categorias\n",
    "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
    "    \n",
    "    # Prepara os subplots\n",
    "    f, ax = plt.subplots(nrows = len(categories), \n",
    "                         ncols = figure_cols, \n",
    "                         figsize = (4 * figure_cols, 4 * len(categories))) \n",
    "    \n",
    "    # Desenha as imagens\n",
    "    for i, cat in enumerate(categories):\n",
    "        \n",
    "        # Extrai uma amostra\n",
    "        sample = df[df[col_name] == cat].sample(figure_cols) \n",
    "        \n",
    "        # Loop pelas colunas da figura\n",
    "        for j in range(0, figure_cols):\n",
    "            \n",
    "            # Extrai o nome da imagem\n",
    "            file = caminho_imagens + sample.iloc[j]['image_id']\n",
    "            \n",
    "            # Lê a imagem do disco\n",
    "            im = imageio.imread(file)\n",
    "            \n",
    "            # Mostra a imagem em gray (preto e branco)\n",
    "            ax[i, j].imshow(im, resample = True, cmap = 'gray')\n",
    "            ax[i, j].set_title(cat, fontsize = 14)  \n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando e Organizando o Primeiro Dataset de Imagens de Raio-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para leitura dos metadados das imagens\n",
    "def leitura_imagens(file_name):\n",
    "\n",
    "    # Leitura da imagem\n",
    "    image = cv2.imread(caminho_imagens + file_name)\n",
    "    \n",
    "    # Extração do número máximo e mínimo de pixels\n",
    "    max_pixel_val = image.max()\n",
    "    min_pixel_val = image.min()\n",
    "    \n",
    "    # image.shape[0] - largura da imagem \n",
    "    # image.shape[1] - altura da imagem \n",
    "    # image.shape[2] - número de canais\n",
    "    # Se o shape não tiver um valor para num_channels (altura, largura) então atribuímos 1 ao número de canais.\n",
    "    if len(image.shape) > 2: \n",
    "        output = [image.shape[0], image.shape[1], image.shape[2], max_pixel_val, min_pixel_val]\n",
    "    else:\n",
    "        output = [image.shape[0], image.shape[1], 1, max_pixel_val, min_pixel_val]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho onde estão as imagens\n",
    "caminho_imagens = imagens_shen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna os metadados das imagens\n",
    "meta_shen = np.stack(df_shen['image_id'].apply(leitura_imagens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava o resultado em um dataframe\n",
    "df = pd.DataFrame(meta_shen, columns = ['largura', 'altura', 'canais', 'maior_valor_pixel', 'menor_valor_pixel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena com o dataset atual\n",
    "df_shen = pd.concat([df_shen, df], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não precisamos mais desse dataframe. Removemos para liberar espaço na memória RAM.\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando e Organizando o Segundo Dataset de Imagens de Raio-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho onde estão as imagens\n",
    "caminho_imagens = imagens_mont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna os metadados das imagens\n",
    "meta_mont = np.stack(df_mont['image_id'].apply(leitura_imagens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava o resultado em um dataframe\n",
    "df = pd.DataFrame(meta_mont, columns = ['largura', 'altura', 'canais', 'maior_valor_pixel', 'menor_valor_pixel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena com o dataset atual\n",
    "df_mont = pd.concat([df_mont, df], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não precisamos mais desse dataframe. Removemos para liberar espaço na memória RAM.\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos Dados em Treino e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de registros\n",
    "df_shen['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de registros\n",
    "df_mont['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos combinar os 2 dataframes \n",
    "df_data = pd.concat([df_shen, df_mont], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E \"embaralhar (shuffle)\" os dados\n",
    "df_data = shuffle(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova coluna chamada 'labels' que mapeia as classes para valores binários (0 ou 1)\n",
    "df_data['labels'] = df_data['target'].map({'Normal':0, 'Tuberculose':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos y (saída)\n",
    "y = df_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos dados de treino e validação\n",
    "df_treino, df_val = train_test_split(df_data, test_size = 0.15, random_state = 101, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando as Imagens Organizadas Por Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo diretório que servirá como base\n",
    "# Você deve alterar o base_dir para oo seu diretório, no Titan ou na sua máquina local\n",
    "base_dir = '/home/dmpm/FIAMED/IAMED/Cap02/Projeto/dados/'\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_base = Path(base_dir)\n",
    "\n",
    "# Verificamos se o diretório já existe e se não existir, criamos\n",
    "if dir_base.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos a criação do diretório com dados de treino\n",
    "dados_treino = os.path.join(base_dir, 'dados_treino/')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_treino = Path(dados_treino)\n",
    "\n",
    "# Verificamos se o diretório já existe e se não existir, criamos\n",
    "if dir_treino.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(dados_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos a criação do diretório com dados de validação\n",
    "dados_val = os.path.join(base_dir, 'dados_val/')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_val = Path(dados_val)\n",
    "\n",
    "# Verificamos se o diretório já existe e se não existir, criamos\n",
    "if dir_val.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(dados_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório para imagens de raio-x Normais para treinamento\n",
    "Normal = os.path.join(dados_treino, 'Normal')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_normal_treino = Path(Normal)\n",
    "\n",
    "# Verificamos se o diretório já existe e se não existir, criamos\n",
    "if dir_normal_treino.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório com imagens de raio-x com Tuberculose para treinamento\n",
    "Tuberculose = os.path.join(dados_treino, 'Tuberculose')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_tb_treino = Path(Tuberculose)\n",
    "\n",
    "# Verificamos se o diretório já existe e se não existir, criamos\n",
    "if dir_tb_treino.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(Tuberculose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório com imagens de raio-x Normais para validação\n",
    "Normal = os.path.join(dados_val, 'Normal')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_normal_val = Path(Normal)\n",
    "\n",
    "# Verificamos se o diretório já existe\n",
    "if dir_normal_val.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório com imagens de raio-x com Tuberculose para validação\n",
    "Tuberculose = os.path.join(dados_val, 'Tuberculose')\n",
    "\n",
    "# Criamos o PATH (caminho)\n",
    "dir_tb_val = Path(Tuberculose)\n",
    "\n",
    "# Verificamos se o diretório já existe\n",
    "if dir_tb_val.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(Tuberculose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora devemos ajustar os índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o image_id como o índice em df_data\n",
    "df_data.set_index('image_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém uma lista de imagens em cada uma das duas pastas originais\n",
    "folder_1 = os.listdir(imagens_shen)\n",
    "folder_2 = os.listdir(imagens_mont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém uma lista de imagens de treino e validação\n",
    "lista_imagens_treino = list(df_treino['image_id'])\n",
    "lista_imagens_val = list(df_val['image_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize das imagens\n",
    "IMAGE_HEIGHT = 96\n",
    "IMAGE_WIDTH = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora copiamos as imagens separadas por classe, redimensionamos e organizamos no novo diretório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfere as imagens de treino pré-processadas para o novo diretório\n",
    "\n",
    "print('\\nPré-processamento dos dados de treino! Aguarde...')\n",
    "\n",
    "# Loop pela lista de imagens de treino\n",
    "for image in lista_imagens_treino:\n",
    "    \n",
    "    # Nome da imagem\n",
    "    fname = image\n",
    "    \n",
    "    # Label da imagem\n",
    "    label = df_data.loc[image,'target']\n",
    "    \n",
    "    # Percorremos a folder_1 (imagens do dataset de shenzen) para buscar o caminho da imagem\n",
    "    if fname in folder_1:\n",
    "        \n",
    "        # Diretório fonte da imagem\n",
    "        src = os.path.join(imagens_shen, fname)\n",
    "        \n",
    "        # Diretório destino da imagem\n",
    "        dst = os.path.join(dados_treino, label, fname)\n",
    "        \n",
    "        # Copia a imagem\n",
    "        image = cv2.imread(src)\n",
    "        \n",
    "        # Aplica o redimensionamento\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Salva a imagem no diretório de destino\n",
    "        cv2.imwrite(dst, image)\n",
    "\n",
    "    # Percorremos a folder_2 (imagens do dataset de montgomery) para buscar o caminho da imagem\n",
    "    if fname in folder_2:\n",
    "        \n",
    "        # Diretório fonte da imagem\n",
    "        src = os.path.join(imagens_mont, fname)\n",
    "        \n",
    "        # Diretório destino da imagem\n",
    "        dst = os.path.join(dados_treino, label, fname)\n",
    "        \n",
    "        # Copia a imagem\n",
    "        image = cv2.imread(src)\n",
    "        \n",
    "        # Aplica o redimensionamento\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Salva a imagem no diretório de destino\n",
    "        cv2.imwrite(dst, image)\n",
    "\n",
    "print('\\nOs dados de treino estão prontos!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfere as imagens de validação pré-processadas para o novo diretório\n",
    "\n",
    "print('\\nPré-processamento dos dados de valiação/teste! Aguarde...')\n",
    "\n",
    "# Loop pela lista de imagens de validação/teste\n",
    "for image in lista_imagens_val:\n",
    "    \n",
    "    # Nome da imagem\n",
    "    fname = image\n",
    "    \n",
    "    # Label da imagem\n",
    "    label = df_data.loc[image,'target']\n",
    "    \n",
    "    # Percorremos a folder_1 (imagens do dataset de shenzen) para buscar o caminho da imagem\n",
    "    if fname in folder_1:\n",
    "        \n",
    "        # Diretório fonte da imagem\n",
    "        src = os.path.join(imagens_shen, fname)\n",
    "        \n",
    "        # Diretório destino da imagem\n",
    "        dst = os.path.join(dados_val, label, fname)\n",
    "        \n",
    "        # Copia a imagem\n",
    "        image = cv2.imread(src)\n",
    "        \n",
    "        # Aplica o redimensionamento\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Salva a imagem no diretório de destino\n",
    "        cv2.imwrite(dst, image)\n",
    "\n",
    "    # Percorremos a folder_2 (imagens do dataset de montgomery) para buscar o caminho da imagem\n",
    "    if fname in folder_2:\n",
    "        \n",
    "        # Diretório fonte da imagem\n",
    "        src = os.path.join(imagens_mont, fname)\n",
    "        \n",
    "        # Diretório destino da imagem\n",
    "        dst = os.path.join(dados_val, label, fname)\n",
    "        \n",
    "        # Copia a imagem\n",
    "        image = cv2.imread(src)\n",
    "        \n",
    "        # Aplica o redimensionamento\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Salva a imagem no diretório de destino\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "print('\\nOs dados de validação/teste estão prontos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Augmentaion (Geração de Imagens Sintéticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classes\n",
    "class_list = ['Normal', 'Tuberculose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de imagens sintéticas desejadas\n",
    "NUM_IMAGENS_SINTETICAS = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria imagens sintéticas para aumentar o volume de dados de treino (não fazemos isso com dados de validação/teste)\n",
    "\n",
    "print('\\nGeração de imagens sintéticas para treinamento! Aguarde...\\n')\n",
    "\n",
    "# Loop pelas imagens de cada classe\n",
    "for item in class_list:\n",
    "    \n",
    "    # Estamos criando diretório temporário aqui porque o excluiremos posteriormente.\n",
    "    # Criamos um diretório base\n",
    "    aug_dir = base_dir + 'temp/'\n",
    "    os.mkdir(aug_dir)\n",
    "    \n",
    "    # Criamos um diretório dentro do diretório base para armazenar imagens da mesma classe\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    # Escolhe a classe\n",
    "    img_class = item\n",
    "\n",
    "    # Listamos todas as imagens no diretório\n",
    "    img_list = os.listdir(dados_treino + img_class)\n",
    "\n",
    "    # Copiamos imagens do diretório de treino para a classe no loop, para o img_dir\n",
    "    for fname in img_list:\n",
    "            \n",
    "            # Diretório fonte da imagem\n",
    "            src = os.path.join(dados_treino + img_class, fname)\n",
    "            \n",
    "            # Diretório destino da imagem\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            \n",
    "            # Copia a imagem da fonte para o destino\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # Apontamos para o diretório contendo as imagens que foram copiadas\n",
    "    path = aug_dir\n",
    "    save_path = dados_treino + img_class\n",
    "\n",
    "    # Criamos um gerador de imagens \n",
    "    datagen = ImageDataGenerator(rotation_range = 10,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 zoom_range = 0.1,\n",
    "                                 horizontal_flip = True,\n",
    "                                 fill_mode = 'nearest')\n",
    "\n",
    "    # Tamanho do batch\n",
    "    batch_size = 50\n",
    "\n",
    "    # Geração de dados\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                              save_to_dir = save_path,\n",
    "                                              save_format = 'png',\n",
    "                                              target_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                              batch_size = batch_size)\n",
    "    \n",
    "    \n",
    "    # Geramos as imagens aumentadas e adicionamos às pastas de treinamento\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    \n",
    "    # Aqui criamos uma quantidade semelhante de imagens para cada classe\n",
    "    num_batches = int(np.ceil((NUM_IMAGENS_SINTETICAS - num_files) / batch_size))\n",
    "\n",
    "    # Executa o gerador e cria imagens aumentadas\n",
    "    for i in range(0, num_batches):\n",
    "        imgs, labels = next(aug_datagen)\n",
    "        \n",
    "    # Exclui o diretório temporário com os arquivos de imagem brutos\n",
    "    shutil.rmtree(aug_dir)\n",
    "    \n",
    "print('\\nOs dados foram criados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de exemplos de treinamento\n",
    "num_amostras_treino = len(df_treino)\n",
    "\n",
    "# Número de exemplos de validação\n",
    "num_amostras_val = len(df_val)\n",
    "\n",
    "# Tamanho do batch de treino\n",
    "batch_size_treino = 10\n",
    "\n",
    "# Tamanho do batch de validação\n",
    "batch_size_val = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passos de treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui definimos o número de passos\n",
    "passos_treino = np.ceil(num_amostras_treino / batch_size_treino)\n",
    "passos_val = np.ceil(num_amostras_val / batch_size_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geramos os batches de dados para treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui geramos os batches de dados\n",
    "datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "# Gera os batches de treino\n",
    "gen_treino = datagen.flow_from_directory(dados_treino,\n",
    "                                         target_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                         batch_size = batch_size_treino,\n",
    "                                         class_mode = 'categorical')\n",
    "\n",
    "# Gera os batches de validação\n",
    "gen_val = datagen.flow_from_directory(dados_val,\n",
    "                                      target_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                      batch_size = batch_size_val,\n",
    "                                      class_mode = 'categorical')\n",
    "\n",
    "# Gera os batches de teste\n",
    "# Nota: shuffle = False faz com que o conjunto de dados de teste não seja \"embaralhado\"\n",
    "gen_teste = datagen.flow_from_directory(dados_val,\n",
    "                                        target_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                        batch_size = batch_size_val,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos os hiperparâmetros que serão usados para treinar o modelo. Esses valores podem ser modificados para ajustar o modelo e tentar obter melhor precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do kernel\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# Tamanho do Pool\n",
    "pool_size = (2,2)\n",
    "\n",
    "# Número de neurônios da primeira camada\n",
    "num_neurons_1 = 32\n",
    "\n",
    "# Número de neurônios da primeira camada\n",
    "num_neurons_2 = 64\n",
    "\n",
    "# Número de neurônios da primeira camada\n",
    "num_neurons_3 = 128\n",
    "\n",
    "# Taxa de dropout nas camadas de convolução\n",
    "dropout_conv = 0.3\n",
    "\n",
    "# Taxa de dropout na camada densa\n",
    "dropout_dense = 0.3\n",
    "\n",
    "# Taxa de aprendizado\n",
    "taxa_aprendizado = 0.0001\n",
    "\n",
    "# Número de épocas de treinamento\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está a arquitetura do modelo. Definimos o número de camadas e a função de ativação usada.\n",
    "\n",
    "Cada problema requer uma arquitetura diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "\n",
    "# Cria a sequência de camadas\n",
    "model = Sequential()\n",
    "\n",
    "# Adicionamos a primeira camada convolucional com 3 operações de convolução\n",
    "# Por que input_shape tem apenas 3 dimensões? Porque iremos alimentar uma imagem por vez durante o treinamento.\n",
    "model.add(Conv2D(num_neurons_1, kernel_size, activation = 'relu', input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "model.add(Conv2D(num_neurons_1, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(num_neurons_1, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "# Adicionamos a segunda camada convolucional com 3 operações de convolução\n",
    "model.add(Conv2D(num_neurons_2, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(num_neurons_2, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(num_neurons_2, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "# Adicionamos a terceira camada convolucional com 3 operações de convolução\n",
    "model.add(Conv2D(num_neurons_3, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(num_neurons_3, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(num_neurons_3, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "# Camada de \"achatamento\"\n",
    "model.add(Flatten())\n",
    "\n",
    "# Camada densa com dropout\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "# Sumário do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(Adam(taxa_aprendizado), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'], \n",
    "              sample_weight_mode = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um diretório para salvar o modelo treinado\n",
    "modelos_base_dir = '/home/dmpm/FIAMED/IAMED/Cap02/Projeto/'\n",
    "modelos_dir = os.path.join(modelos_base_dir, 'modelos/')\n",
    "\n",
    "# Define o Path\n",
    "dir_modelos = Path(modelos_dir)\n",
    "\n",
    "if dir_modelos.exists():\n",
    "    print('O diretório já existe. Delete no SO e tente novamente.')\n",
    "else:\n",
    "    os.mkdir(modelos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome completo do modelo a ser salvo\n",
    "modelo_salvo = modelos_dir + 'modelo_raiox.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos um checkpoint para verificar regularmente se a acurácia em validação melhorou\n",
    "# Se a performance melhorar em validação salvamos o modelo\n",
    "# Podemos ainda optar por salvar o modelo a cada número de épocas\n",
    "checkpoint = ModelCheckpoint(modelo_salvo, \n",
    "                             monitor = 'val_accuracy', \n",
    "                             verbose = 1, \n",
    "                             save_best_only = True, \n",
    "                             mode = 'max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa estratégia é reduzir a taxa de aprendizado de forma gradativa, sempre que o modelo parar de aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redução gradual da taxa de aprendizado (Reduce on Plateau)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                              factor = 0.5, \n",
    "                              patience = 2, \n",
    "                              verbose = 1, \n",
    "                              mode = 'max', \n",
    "                              min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os callbacks que serão usados no treinamento\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(gen_treino, \n",
    "                    steps_per_epoch = passos_treino, \n",
    "                    validation_data = gen_val,\n",
    "                    validation_steps = passos_val,\n",
    "                    epochs = num_epochs, \n",
    "                    verbose = 1,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os nomes das métricas do modelo\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos o modelo treinado\n",
    "model.load_weights('modelos/modelo_raiox.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraímos as métricas de treinamento\n",
    "val_loss, val_acc = model.evaluate_generator(gen_val, steps = passos_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar a curva de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai as métricas\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.plot(epochs, acc, '-', label = 'Acurácia em Treinamento', color = 'blue')\n",
    "plt.title('Acurácia em Treinamento')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, '-', label = 'Erro em Treinamento', color = 'red')\n",
    "plt.title('Erro em Treinamento')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.plot(epochs, val_acc, '-', label = 'Acurácia em Validação', color = 'green')\n",
    "plt.title('Acurácia em Validação')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, val_loss, '-', label = 'Erro em Validação', color = 'magenta')\n",
    "plt.title('Erro em Validação')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos obter os labels dos dados de teste\n",
    "labels_teste = gen_teste.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos dos labels para o plot da matriz de confusão\n",
    "labels_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos a etiqueta (label) associada a cada classe\n",
    "gen_teste.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazemos as previsões\n",
    "previsoes = model.predict_generator(gen_teste, steps = passos_val, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar uma Matriz de Confusão - Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para a Matriz de Confusão\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Matriz de Confusão',\n",
    "                          cmap = plt.cm.YlOrRd):\n",
    "\n",
    "    # Se normalize = True, obtemos a matriz de confusão com dados normalizados\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Matriz de Confusão Normalizada\")\n",
    "    else:\n",
    "        print('Matriz de Confusão Sem Normalização')\n",
    "\n",
    "    # Mostramos a Matriz de Confusão\n",
    "    print(cm)\n",
    "\n",
    "    # Plot\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    # Plot do texto\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), \n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Label Verdadeiro')\n",
    "    plt.xlabel('Label Previsto')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função argmax() retorna o índice do valor máximo em uma linha\n",
    "matriz_conf = confusion_matrix(labels_teste, previsoes.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels dos dados de teste\n",
    "gen_teste.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos os rótulos dos labels da classe. Eles precisam corresponder a ordem mostrada acima.\n",
    "matriz_conf_plot_labels = ['Normal', 'Tuberculose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E então criamos o plot\n",
    "plot_confusion_matrix(matriz_conf, matriz_conf_plot_labels, title = 'Matriz de Confusão')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geramos a sequência na qual o gerador processou as imagens de teste\n",
    "imagens_teste = gen_teste.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtemos os rótulos verdadeiros\n",
    "y_true = gen_teste.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtemos os rótulos previstos\n",
    "y_pred = previsoes.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatório de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o relatório de classificação\n",
    "report = classification_report(y_true, y_pred, target_names = matriz_conf_plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalho concluído. Agora vamos preparar o modelo para o deploy (publicação)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação Para o Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualiza o TensorFlow\n",
    "!pip install -q -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pacote tensorflowjs\n",
    "!pip install -q tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o formato do modelo para usar com aplicação web\n",
    "!tensorflowjs_converter --input_format keras modelos/modelo_raiox.h5 modelos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "cnnp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
